{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "127dd72e-7ed6-4e6b-8864-be0b479ccf2e",
   "metadata": {},
   "source": [
    "# Train Image Classifiers\n",
    "\n",
    "In this notebook we will train an image classifier that classify fruit images, using MMClassificaiton."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22298ae9-0024-4e86-a903-4981053f5424",
   "metadata": {},
   "source": [
    "## Prepare a Dataset\n",
    "\n",
    "We have already prepared a dataset.\n",
    "\n",
    "Credit to Zihao: https://github.com/TommyZihao/MMClassification_Tutorials\n",
    "\n",
    "To download and extract the dataset, in command line:\n",
    "```\n",
    "curl -O https://zihao-openmmlab.obs.myhuaweicloud.com/20220716-mmclassification/dataset/fruit30/fruit30_split.zip\n",
    "unzip -d data fruit30_split.zip\n",
    "```\n",
    "\n",
    "The dataset should be categorized by folders, for MMClassification to read."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd9fc5f-d7a7-4bf4-8c43-ab7156e81831",
   "metadata": {},
   "source": [
    "## Prepare a Config and Checkpoint File\n",
    "\n",
    "For speed consideration, we use a lightweight neural network, MobileNetV2.\n",
    "\n",
    "we use mim to download the config file and checkpoint file.\n",
    "\n",
    "```\n",
    "mim download mmcls --config mobilenet-v2_8xb32_in1k --dest .\n",
    "mv mobilenet-v2_8xb32_in1k.py mobilenet-v2_fruit.py\n",
    "```\n",
    "\n",
    "If you prefer to play with other models, navigate to [MMClassification model zoo](https://mmclassification.readthedocs.io/en/latest/model_zoo.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ca0906-acf9-4096-878a-7504e0d0622a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mim download mmcls --config mobilenet-v2_8xb32_in1k --dest .\n",
    "!mv mobilenet-v2_8xb32_in1k.py mobilenet-v2_fruit.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e6ada9-8978-495c-86e2-a965799ddbb9",
   "metadata": {},
   "source": [
    "## Modify the Config File\n",
    "\n",
    "1. Remove some intermediate item for clean: `dataset_type`, `img_norm_cfg`, `train_pipeline`, `test_pipeline`\n",
    "1. Modify model\n",
    "    1. number of class: from 1000 to 30\n",
    "    2. pretrain weights: from None to the downloaded checkpoint file, as we finetune the model instead of training from scratch\n",
    "1. Data: for train/val/test \n",
    "    1. `type`: `ImageNet` -> `CustomDataset`\n",
    "    2. `prefix`, which is the root path to images: modify to `\"data/fruit30_split/train\"` or `\"data/fruit30_split/val\"`\n",
    "    3. `ann_file`, use folder name as class name: modify to `None`\n",
    "1. Runner and Optimizer\n",
    "    1. number of training epochs: `runner.max_epochs`\n",
    "    1. learning rates: `optimizer.lr`, usually divided by 8 due to linear scaling rules.\n",
    "1. Misc\n",
    "    1. Decrease `log_confg.interval` for small computation power\n",
    "    1. Increase `checkpoint_config.interval` to avoid saving too many checkpoint, to same time and disk space\n",
    "1. Further parameter tuning you may try\n",
    "    1. learning rates: Decrease `optimizer.lr` for finetuning \n",
    "    1. configure learning scheduler to decrease learning when loss saturates. Moreover, by setting `by_epoch=False`, we decrease learning rate by iteration instead of by epoches.\n",
    "    1. Monitor loss decrease and re-tune\n",
    "    1. More available lr_schedulers are available in [mmcv](https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/lr_updater.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8071497-dd81-4121-b2b0-91df11d41734",
   "metadata": {},
   "source": [
    "## Launch Training\n",
    "\n",
    "In command line\n",
    "\n",
    "```\n",
    "mim train mmcls mobilenet-v2_fruit.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b69849c-3f89-4446-b9de-970e7f47f33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mim train mmcls mobilenet-v2_fruit.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da09fe8-4d5c-43d5-9456-0e7bcf8e740c",
   "metadata": {},
   "source": [
    "## Understand Logs\n",
    "\n",
    "\n",
    "The log is long but mainly contains the following parts:\n",
    "\n",
    "1. Toolbox information\n",
    "2. Dumped Config files\n",
    "3. Model Initialization Logs\n",
    "    1. Check `mmcls - INFO - load checkpoint from local path: mobilenet_v2_batch256_imagenet_20200708-3b2dc3af.pth`, which means pretrained weights are loaded correctly.\n",
    "4. Information on Hooks: we don't configure this explicitly in this tutorial, so ignore that\n",
    "5. Training progress\n",
    "    1. Training logs: including current learning, training loss, time consumption, memory occupation\n",
    "    2. Validation logs: Accuracy on validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515824b8-39f0-415f-8636-76f2cb7423f7",
   "metadata": {},
   "source": [
    "## Test the Model\n",
    "\n",
    "The trained model (checkpoint file) is usually saved under `work_dirs/{experiment_name}/latest.pth`. \n",
    "We can load it to test with a new image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c30d1a-25d6-4fac-8aee-21003c6c8109",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcls.apis import init_model, inference_model\n",
    "\n",
    "model = init_model('mobilenet-v2_fruit.py', 'work_dirs/mobilenet-v2_fruit/latest.pth')\n",
    "result = inference_model(model, 'banana.png')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b36d5d6-bacf-4cf7-86f4-0b3b54230a73",
   "metadata": {},
   "source": [
    "## PyTorch codes under the hood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f17de7-87ab-4069-9961-dbdfb6615e26",
   "metadata": {},
   "source": [
    "### Runner\n",
    "\n",
    "Runner construct the framework of training.\n",
    "\n",
    "Specifically, MMClassification is based on `mmcv.EpochBasedRunner`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afa5035-6b79-4c15-ba05-a06d339d7524",
   "metadata": {},
   "source": [
    "## PyTorch codes under the hood\n",
    "\n",
    "- train.py \n",
    "    - Process configs\n",
    "    - Build dataset object\n",
    "    - Build model object\n",
    "    - call `mmcls.apis.train_model(model, dataset, cfg, **kwargs)`\n",
    "        - Build dataloader object\n",
    "        - Build optimizer object\n",
    "        - Build runner via `runner.EpochBasedRunner(model, optimizer)`\n",
    "        - Call `runner.run(dataloader)`\n",
    "            - Fetch `batch` from `dataloader`\n",
    "                - Data augmentation via `train_pipeline`\n",
    "            - Call `losses = model.train_step(data_batch)`\n",
    "            - `loss.backward()` and `optimizer.step()` in throuth `mmcv.OptimizerHook.after_train_iter()` hook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61ab82e-f884-4133-b333-4d0736a9f1ea",
   "metadata": {},
   "source": [
    "`tools/train.py`\n",
    "```python\n",
    "def main():\n",
    "    model = build_classifier(cfg.model)\n",
    "    model.init_weights()\n",
    "\n",
    "    datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "    train_model(\n",
    "        model,\n",
    "        datasets,\n",
    "        cfg,\n",
    "        distributed=distributed,\n",
    "        validate=(not args.no_validate),\n",
    "        timestamp=timestamp,\n",
    "        device=cfg.device,\n",
    "        meta=meta)\n",
    "```\n",
    "\n",
    "\n",
    "`mmcls/apis/train_model.py`\n",
    "```python\n",
    "def train_model(model,\n",
    "                dataset,\n",
    "                cfg):\n",
    "    \n",
    "    data_loaders = [build_dataloader(ds, **train_loader_cfg) for ds in dataset]\n",
    "\n",
    "    optimizer = build_optimizer(model, cfg.optimizer)\n",
    "    \n",
    "    runner = build_runner(\n",
    "        cfg.runner,\n",
    "        default_args=dict(\n",
    "            model=model,\n",
    "            optimizer=optimizer))\n",
    "    \n",
    "    runner.register_training_hooks(\n",
    "        cfg.lr_config,\n",
    "        optimizer_config,\n",
    "        cfg.checkpoint_config,\n",
    "        cfg.log_config,\n",
    "        cfg.get('momentum_config', None),\n",
    "        custom_hooks_config=cfg.get('custom_hooks', None))\n",
    "    \n",
    "    runner.run(data_loaders, cfg.workflow)\n",
    "```\n",
    "\n",
    "\n",
    "`mmcv/runner/epoch_based_runner.py`\n",
    "```python\n",
    "class EpochBasedRunner(BaseRunner):\n",
    "\n",
    "    def run_iter(self, data_batch: Any, train_mode: bool, **kwargs) -> None:\n",
    "        if train_mode:\n",
    "            outputs = self.model.train_step(data_batch, self.optimizer, **kwargs)\n",
    "        else:\n",
    "            outputs = self.model.val_step(data_batch, self.optimizer, **kwargs)\n",
    "\n",
    "        self.outputs = outputs\n",
    "\n",
    "    def train(self, data_loader, **kwargs):\n",
    "        self.model.train()\n",
    "        self.data_loader = data_loader\n",
    "        for i, data_batch in enumerate(self.data_loader):\n",
    "            self.run_iter(data_batch, train_mode=True, **kwargs)\n",
    "            self.call_hook('after_train_iter')\n",
    "```\n",
    "\n",
    "\n",
    "`mmcls/models/classifiers/base.py`\n",
    "```python\n",
    "class BaseClassifier(BaseModule, metaclass=ABCMeta):\n",
    "    \n",
    "    def forward(self, img, return_loss=True, **kwargs):\n",
    "        \"\"\"Calls either forward_train or forward_test depending on whether\n",
    "        return_loss=True.\n",
    "\n",
    "        Note this setting will change the expected inputs. When\n",
    "        `return_loss=True`, img and img_meta are single-nested (i.e. Tensor and\n",
    "        List[dict]), and when `resturn_loss=False`, img and img_meta should be\n",
    "        double nested (i.e.  List[Tensor], List[List[dict]]), with the outer\n",
    "        list indicating test time augmentations.\n",
    "        \"\"\"\n",
    "        if return_loss:\n",
    "            return self.forward_train(img, **kwargs)\n",
    "        else:\n",
    "            return self.forward_test(img, **kwargs)\n",
    "\n",
    "    def train_step(self, data, optimizer=None, **kwargs):\n",
    "        losses = self(**data)\n",
    "        loss, log_vars = self._parse_losses(losses)\n",
    "\n",
    "        outputs = dict(\n",
    "            loss=loss, log_vars=log_vars, num_samples=len(data['img'].data))\n",
    "\n",
    "        return outputs\n",
    "```\n",
    "\n",
    "\n",
    "`mmcls/models/classifiers/image.py`\n",
    "```python\n",
    "class ImageClassifier(BaseClassifier):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 backbone,\n",
    "                 neck=None,\n",
    "                 head=None,\n",
    "                 pretrained=None,\n",
    "                 train_cfg=None,\n",
    "                 init_cfg=None):\n",
    "        super(ImageClassifier, self).__init__(init_cfg)\n",
    "\n",
    "        if pretrained is not None:\n",
    "            self.init_cfg = dict(type='Pretrained', checkpoint=pretrained)\n",
    "        self.backbone = build_backbone(backbone)\n",
    "\n",
    "        if neck is not None:\n",
    "            self.neck = build_neck(neck)\n",
    "\n",
    "        if head is not None:\n",
    "            self.head = build_head(head)\n",
    "\n",
    "    def extract_feat(self, img):\n",
    "        x = self.backbone(img)\n",
    "\n",
    "        if self.with_neck:\n",
    "            x = self.neck(x)\n",
    "            \n",
    "        return x\n",
    "\n",
    "    def forward_train(self, img, gt_label, **kwargs):\n",
    "        x = self.extract_feat(img)\n",
    "\n",
    "        losses = dict()\n",
    "        loss = self.head.forward_train(x, gt_label)\n",
    "\n",
    "        losses.update(loss)\n",
    "\n",
    "        return losses\n",
    "```\n",
    "\n",
    "\n",
    "`mmcv/runner/hooks/optimizer.py`\n",
    "```python\n",
    "class OptimizerHook(Hook):\n",
    "    def after_train_iter(self, runner):\n",
    "        runner.optimizer.zero_grad()\n",
    "        runner.outputs['loss'].backward()\n",
    "        runner.optimizer.step()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
