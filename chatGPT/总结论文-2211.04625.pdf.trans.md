# chatGPT 分析报告
## 

# 标题
Soft Augmentation for Image Classiﬁcation

# 收录会议或期刊
CVPR 2021

# 作者
Yang Liu, Shen Yan, Laura Leal-Taixé, James Hays, Deva Ramanan Argo AI

# 作者邮箱
youngleoel@gmail.com, shenyan@google.com, leal.taixe@tum.de, hays@gatech.edu, deva@cs.cmu.edu

# 编号
无编号信息

# 摘要
现代神经网络存在过度参数化的问题，因此依赖于强大的正则化，如数据增强和权重衰减，以减少过拟合并提高泛化性能。主导形式的数据增强应用于不变的变换，其中样本的学习目标对应于应用于该样本的变换是不变的。我们从人类视觉分类研究中吸取灵感，提出将不变变换推广到软增强，其中学习目标随着应用于样本的变换程度而软化为非线性函数。例如，更激进的图像裁剪增强会产生更不自信的学习目标。我们证明软目标允许更激进的数据增强，提供更强大的性能提升，与其他增强策略配合使用，并且有趣的是，产生更好的模型校准（因为它们训练成在被激进地裁剪/遮挡的示例上不那么自信）。

---

---

---



## 

现代的神经网络通常具有过高的参数数量，因此需要对其进行强有力的正则化，例如数据增强和权重衰减以减少过拟合并提高泛化性能。主要的数据增强形式应用于不变转换，其中样本的学习目标对于应用于该样本的转换是不变的。与此相关的，我们从人类视觉分类研究中获得了启示，并提出将不变转换的增强推广到软增强。在这种情况下，将被转换后的训练样本的学习目标进行软化，该学习目标随着对样本应用的转换程度而非线性减弱，例如更激进的图像裁剪增强会产生不确定的学习目标。我们证明软目标允许更激进的数据增强，提供更稳健的性能提升，适用于其他增强策略，并且有趣的是可以产生更好的校准模型。结合现有的激进增强策略，软目标1）将Cifar-10，Cifar-100，ImageNet-1K和ImageNet-V2的Top-1准确度提高了一倍，2）将模型遮挡性能提高了4倍，3）减少了期望校准误差（ECE）的一半。最后，我们展示软增强泛化到自监督分类任务。

## 

[Local Message] 线程1在执行过程中遭遇问题, Traceback：

```
Traceback (most recent call last):
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\site-packages\urllib3\response.py", line 444, in _error_catcher
    yield
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\site-packages\urllib3\response.py", line 828, in read_chunked
    self._update_chunk_length()
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\site-packages\urllib3\response.py", line 758, in _update_chunk_length
    line = self._fp.fp.readline()
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\ssl.py", line 1274, in recv_into
    return self.read(nbytes, buffer)
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\ssl.py", line 1130, in read
    return self._sslobj.read(len, buffer)
TimeoutError: The read operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\site-packages\requests\models.py", line 816, in generate
    for chunk in self.raw.stream(chunk_size, decode_content=True):
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\site-packages\urllib3\response.py", line 624, in stream
    for line in self.read_chunked(amt, decode_content=decode_content):
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\site-packages\urllib3\response.py", line 816, in read_chunked
    with self._error_catcher():
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\site-packages\urllib3\response.py", line 449, in _error_catcher
    raise ReadTimeoutError(self._pool, None, "Read timed out.")
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\workspace\python\chatgpt_academic\request_llm\bridge_chatgpt.py", line 106, in predict_no_ui_long_connection
    try: chunk = next(stream_response).decode()
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\site-packages\requests\models.py", line 866, in iter_lines
    for chunk in self.iter_content(
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\site-packages\requests\models.py", line 823, in generate
    raise ConnectionError(e)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\workspace\python\chatgpt_academic\crazy_functions\crazy_utils.py", line 47, in _req_gpt
    gpt_say = predict_no_ui_long_connection(
  File "E:\workspace\python\chatgpt_academic\request_llm\bridge_chatgpt.py", line 110, in predict_no_ui_long_connection
    chunk = next(stream_response).decode() # 失败了，重试一次？再失败就没办法了。
StopIteration
```

此线程失败前收到的回答：人类视觉分类可以抵御遮挡等干扰

## 

本研究首先提出从缩放的正态分布S∗∼N（0，σL）中独立抽取tx、ty（要剪裁以满足|tx|<L，|ty|<L），其中L是图像较长边长度（对于Cifar L=32）。该分布具有零均值，并且σ控制分布的相对扩展程度，因此也控制着平均遮挡水平。根据正态分布的3σ法则，一个直观的、无需调整的选择是将σ设置为0.3左右，其中大约99%的裁剪样本的可见度≥0。改变分布而不提供目标软化可以提供中等的0.4%的提升。类似于标签平滑，可以定义一种自适应软化α（tx，ty，k），使得目标结果更加软化。可以将硬目标软化为置信度p∈[0，1]。通过考虑产生给定裁剪参数tx，ty和曲线形状k的目标硬度p的幂函数族，而不是一个固定的α：其中v（tx，ty）∈[0，1]是图像可见性，它是tx和ty的函数。幂函数族是一个简单的一参数形式，它允许我们测试线性（k=1）和非线性（k≠1）软化：更高的k提供在高可见度区域的平坦平台（见图2右侧）。如标签平滑所示，p可以被看作是单热的学习目标的基本事实类概率。pmin是取决于任务先验的概率。例如，对于Cifar-100，pmin=1＃classes= 0.01。方程7有三个假设：1）信息丢失是图像可见性的函数，且当图像完全遮挡时，所有信息都会丢失；2）训练图像的原始标签具有100%的置信度，这表明标签的类别是确定的；3）所有图像的信息损失可以通过单个置信度-可见度曲线近似。虽然第一种假设得到了人类视觉分类研究的证明，并且第4.2节和4.3节的经验证据表明第二个和第三个假设近似成立，但这些假设的局限性将在第5节中讨论。正如方程4、5和6所建议的，将三个版本的Soft Augmentation与Label Smoothing在不同的裁剪强度σ下进行比较。流行的ResNet-18模型在100类分类Cifar-100训练集上进行训练。在验证集上报告了Top-1误差减少（详情见附录B）。与之前的研究一致，当平滑因子α被妥善调整时，标签平滑可以提高模型的性能约1.3％（图3左侧）。用k=2和σ≈0.3结合目标和权重软化（方程6）可以提高模型性能2.5%（图3右侧）。 k = 2在定性上类似于Tang等人报道的人类视觉置信度在遮挡下的曲线形状。有趣的是，σ≈0.3的最佳值符合直觉的3σ法则。在下一节中，我们冻结k = 2和σ = 0.3，并展示了适用于Cifar-10、ImageNet-1K和ImageNet-V2任务的稳健改进。

## 

本部分研究了Soft Augmentation在模型和任务上的鲁棒性，以及与更复杂的数据增强策略如RandAugment的比较和工作效果。与CIFAR数据集相比，ImageNet-1K数据集的图像更大且变化大小不一。与CIFAR的固定裁剪增强相反，ImageNet训练配方中标准的裁剪和缩放增强t(tx,ty,w,h)(x)具有随机位置tx，ty和随机大小w，h。缩放步骤是产生固定大小的训练图像（例如224×224）所必需的。我们遵循相同的σ = 0.3原则为tx、ty和w、h进行绘制（详情见附录B）。比较单个方法，只有裁剪的Soft Augmentation表现一致优于具有14个变换的更复杂的RandAugment(Table 2)。在Cifar-10/100上使用SA训练的小型ResNet-18模型甚至优于更大的基线ResNet-50[39]和WideResNet-28[50]模型。
由于RandAugment是一种搜索策略，最初规定要与标准裁剪增强一起应用[8]，因此可以轻松地将标准裁剪替换为软裁剪，并结合Soft Augmentation和RandAugment。正如表2所示，Soft Augmentation通过提高其top-1错误率减少来增强RandAugment的效果和表现跨数据集和模型(Table 2)。请注意，在Cifar-100上使用SA训练的小型ResNet-18模型的固定RandAugment方法略微降低了其性能。与Cubuk等人[8]的观察一致，RandAugment的最佳超参数取决于模型容量和任务复杂性的组合。尽管RandAugment单独应用会损失性能，但添加Soft Augmentation则反转了这种影响并提高了2.7%的性能。对于前面的实验，使用k = 2的固定软化曲线进行Soft Augmentation，并实现官方的PyTorch RandomAugment来确保公平比较和评估鲁棒性。可以微调每个模型和任务的超参数以实现更好的实证性能。

如第2节所述，对遮挡的鲁棒性在人类视觉[34,44,54]和计算机视觉[22,46,47]中都是视觉模型作为对象的现实应用中的重要属性。为了评估Soft Augmentation对计算机视觉模型的遮挡鲁棒性的影响，使用ResNet-50模型对遮挡的ImageNet验证图像进行了测试(图4和附录图7)。使用随机放置的正方形图块遮挡占据图像面积的λ%，λ设置为{0%，20%，40%，60%，80%}以创建遮挡级别范围。如图5所示，RandAugment（RA）和Soft Augmentation（SA）独立地提高了不同遮挡级别下的遮挡鲁棒性。将RA与SA结合可将Top-1错误率减少高达17%。在80%遮挡水平下，SA的鲁棒性优于RA。

## 

[Local Message] 线程4在执行过程中遭遇问题, Traceback：

```
Traceback (most recent call last):
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\site-packages\urllib3\response.py", line 444, in _error_catcher
    yield
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\site-packages\urllib3\response.py", line 828, in read_chunked
    self._update_chunk_length()
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\site-packages\urllib3\response.py", line 758, in _update_chunk_length
    line = self._fp.fp.readline()
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\ssl.py", line 1274, in recv_into
    return self.read(nbytes, buffer)
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\ssl.py", line 1130, in read
    return self._sslobj.read(len, buffer)
TimeoutError: The read operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\site-packages\requests\models.py", line 816, in generate
    for chunk in self.raw.stream(chunk_size, decode_content=True):
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\site-packages\urllib3\response.py", line 624, in stream
    for line in self.read_chunked(amt, decode_content=decode_content):
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\site-packages\urllib3\response.py", line 816, in read_chunked
    with self._error_catcher():
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\site-packages\urllib3\response.py", line 449, in _error_catcher
    raise ReadTimeoutError(self._pool, None, "Read timed out.")
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\workspace\python\chatgpt_academic\request_llm\bridge_chatgpt.py", line 106, in predict_no_ui_long_connection
    try: chunk = next(stream_response).decode()
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\site-packages\requests\models.py", line 866, in iter_lines
    for chunk in self.iter_content(
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\site-packages\requests\models.py", line 823, in generate
    raise ConnectionError(e)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\workspace\python\chatgpt_academic\crazy_functions\crazy_utils.py", line 47, in _req_gpt
    gpt_say = predict_no_ui_long_connection(
  File "E:\workspace\python\chatgpt_academic\request_llm\bridge_chatgpt.py", line 110, in predict_no_ui_long_connection
    chunk = next(stream_response).decode() # 失败了，重试一次？再失败就没办法了。
StopIteration
```

此线程失败前收到的回答：除了top

## 

我们将人类视觉研究中的定性形状作为启发，特别是人类视觉分类性能随图像遮挡的非线性降低。我们在此基础上提出了将不变变换与软性增强相结合的Soft Augmentation方法，其中学习目标（如one-hot向量和/或样本权重）的非线性软化程度随着应用于样本的变换程度而软化。以裁剪变换为例，我们实证表明Soft Augmentation在Cifar-10、Cifar-100、ImageNet-1K和ImageNet-V2上提供了强大的top-1误差降低效果。在固定软化曲线的情况下，Soft Augmentation使得在模型和数据集中的top-1精度提高了一倍，并将模型的遮挡性能提高了最多4倍。将Soft Augment与最近开发的Trivial Augment相结合，可以同时提高模型的准确性和校准性，甚至超越计算密集的五合一模型。最后，自监督学习实验表明，Soft Augmentation也适用于超越受监督的one-hot分类设置的其他任务。一些未来的方向包括将软增强多样性扩展到裁剪之外的增强方法，使得Soft Augment可以适应每个类别或样本的自适应变换。此外，将Soft Augment应用于其他视觉和非视觉任务也是一个有趣的方向。

## 

[Local Message] 线程6在执行过程中遭遇问题, Traceback：

```
Traceback (most recent call last):
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\site-packages\urllib3\response.py", line 444, in _error_catcher
    yield
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\site-packages\urllib3\response.py", line 828, in read_chunked
    self._update_chunk_length()
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\site-packages\urllib3\response.py", line 758, in _update_chunk_length
    line = self._fp.fp.readline()
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\ssl.py", line 1274, in recv_into
    return self.read(nbytes, buffer)
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\ssl.py", line 1130, in read
    return self._sslobj.read(len, buffer)
TimeoutError: The read operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\site-packages\requests\models.py", line 816, in generate
    for chunk in self.raw.stream(chunk_size, decode_content=True):
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\site-packages\urllib3\response.py", line 624, in stream
    for line in self.read_chunked(amt, decode_content=decode_content):
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\site-packages\urllib3\response.py", line 816, in read_chunked
    with self._error_catcher():
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\site-packages\urllib3\response.py", line 449, in _error_catcher
    raise ReadTimeoutError(self._pool, None, "Read timed out.")
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\workspace\python\chatgpt_academic\request_llm\bridge_chatgpt.py", line 106, in predict_no_ui_long_connection
    try: chunk = next(stream_response).decode()
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\site-packages\requests\models.py", line 866, in iter_lines
    for chunk in self.iter_content(
  File "C:\Users\zxsx\anaconda3\envs\pygit\lib\site-packages\requests\models.py", line 823, in generate
    raise ConnectionError(e)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\workspace\python\chatgpt_academic\crazy_functions\crazy_utils.py", line 47, in _req_gpt
    gpt_say = predict_no_ui_long_connection(
  File "E:\workspace\python\chatgpt_academic\request_llm\bridge_chatgpt.py", line 110, in predict_no_ui_long_connection
    chunk = next(stream_response).decode() # 失败了，重试一次？再失败就没办法了。
StopIteration
```

此线程失败前收到的回答：本文介绍了一些在计算机视觉领域中被广泛使用的神经网络模

## 

该段落介绍了几篇论文。第30篇论文提出了一种基于距离感知的简单且有原则的确定性深度学习不确定性估计方法。第31篇论文讨论了一种基于能量的超出分布检测方法。第32篇论文提出了一种神经网络架构感知优化方法。第33篇论文介绍了一种带有热启动功能的随机梯度下降方法。第34篇论文提出了一种基于局部尺度不变特征的物体识别方法。第35篇论文提出了一种简单的确定性不确定性估计基线方法。第36篇论文在标签平滑方面进行了讨论。第37篇论文介绍了一种自由调整且最先进的数据增强方法。第38篇论文介绍了 PyTorch，一个命令式风格、高性能的深度学习库。第39篇论文探讨了图像分类器是否能推广到图像分类任务上。第40篇论文介绍了一种学习重新加权示例以实现鲁棒深度学习的方法。第41篇论文讨论了如何利用深度学习改善蛋白质结构预测的方法。第42篇论文提出了一种卷积神经网络方法，并深入探讨了其原理。第43篇论文重构了Inception体系结构，以用于计算机视觉任务。最后，第44篇和第45篇论文提出了不同方法的深度学习模型，以用于图像处理任务，并进行了相关实验和验证。

## 

本文列举了几篇与数据增强相关的研究论文，包括上下文感知组合网络、循环处理促进物体识别、最大期望损失的样本重新加权、局部化特征的强分类器的正则化策略和标签平滑等。作者进行了Cifar-100实验，使用Soft Augmentation + Trivial Augment（SA+TA）对数据进行增强，并将其与其他方法进行了比较，包括Mixup、Cutout和Online Label Smoothing等。结果表明，SA+TA可以显著提高模型的准确性，其效果比其他方法更好。此外，作者还发现，在训练末期降低裁剪强度可以略微改善对Cifar-100数据的准确性。

## 

表格6：通过加性噪声进行软数据增广可提高在Cifar-100上的ResNet18性能。给定一张图像X和一个随机噪声模式Xnoise，增广图像由Xaug = X + αXnoise得到，其中α来自于N(0,0.1)，Xnoise的像素值也是从N(0,0.1)独立地选择的。在基准线以及软增广（裁剪+RandAugment）上应用软增广可以提高性能。所有ImageNet-1k实验都采用分布式批处理大小为256，分布在4个NVIDIA V100 16GB GPU上在AWS上进行。水平翻转在所有实验中作为基本无损增广使用。基础学习率设置为0.1，有一个5个epoch的线性预热过程，并在270个epoch内使用余弦衰减。一个ResNet-50训练的单次运行需要大约4 x 4 = 16个GPU天，且ImageNet实验总共需要600个GPU天。我们使用RandAugment和ResNet-50/101（BSD样式许可证）的官方PyTorch [38]实现，并在所有实验中使用标准的方形输入Linput = W = H = 224。值得注意的是，原始的RandAugment [8]使用更大的输入尺寸，即H = 224，W = 244，但是我们重新实现的ResNet-50的top-1错误率（22.02 vs 22.4）比使用更小的输入尺寸的情况要好。ImageNet-V2是由He等人提出的验证集[39]。对于训练，标准裁剪变换有4个超参数，其中(scalemin, scalemax)定义了裁剪图像与原始图像的相对大小的范围，(ratiomin, ratiomax)确定了最终调整大小之前裁剪路径的宽高比的下限和上限。在实践中，从均匀分布U(scalemin, scalemax)中选取一个比例，然后从均匀分布U(log(ratiomin), log(ratiomax))中选择宽高比数值的对数。默认值为scalemin = 0.08，scalemax = 1.0，ratiomin = 3/4，ratiomax = 4/3。与我们的Cifar裁剪增强类似，我们提出了一个简化的ImageNet裁剪增强，只使用2个超参数σ，Lmin。首先，我们从一个剪裁的、修剪的截断纪实分布N R(0, σ(L-Lmin))中绘制∆w、∆h，得到w = W - ∆w，h = H - ∆h。Lmin是裁剪图像的最小分辨率，并设置为输入分辨率的一半：224/2 = 112。然后，tx、ty从N(0，σ(W+w))和N(0，σ(H+h))中独立地选择。注意，我们使用一组固定的直观值σ = 0.3，Lmin = 1/2Linput = 112来进行所有实验。对于模型验证，标准的增广实践首先调整图像的短边，使其长度为Linput = 256，然后应用一个中心224 x 224的裁剪。注意，Linput是测试增广引入的另一个超参数。相比之下，我们通过将Linput设置为最终输入大小224来简化了这个过程，并在所有ImageNet模型评估中使用了这个配置。

自监督SimSiam实验在单个Nvidia A6000 GPU上运行。我们遵循标准的两步训练流程[6]。1)我们首先用自监督的方式在500个epoch内训练孪生网络以学习视觉特征，采用余弦衰减调度和批处理大小为512。我们只在此步骤中应用软增广。2)然后使用基准真实标签对线性层进行微调，使用初始学习率为10和在第60和80个epoch时进行10倍衰减，共进行100个epoch。根据[6]，设置scalemin = 0.2，scalemax = 1.0，ratiomin = 3/4，ratiomax = 4/3。由于批量中降权训练样本有效地降低了学习率，并且SimSiam对它很敏感，因此我们对一个批次中的权重进行了归一化，使平均值保持为1，并重新调整了学习率（表7）。

表7：软增广改善SimSiam的自监督学习。报告了ResNet-18三次运行的平均±标准误验证错误率。

如果是硬性的一个-hot真实标签的情况，其中ytrue n∗ = 1，ytrue n = 0，n ̸= n∗，那么采用默认的权重w=1，则它将退化为交叉熵损失。现在我们将标签软化为ytrue n∗ = p，ytrue n = (1-p)/(N-1) = q，其中n ̸= n∗：

如果q未分布，并且ytrue n=0，n ̸= n∗（这种配置不对应我们的任何实验），则：注意，p不是模型权重的函数，因此当我们对模型权重取导数来计算梯度时，方程式16和17将得到相同的梯度。当一个hot标签和权重都由p软化时：

